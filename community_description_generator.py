"""
ç¤¾åŒºæè¿°ç”Ÿæˆå™¨ - ä½¿ç”¨å¼‚æ­¥å¹¶å‘DeepSeekåˆ†æ
"""

import asyncio
import json
import logging
import time
from typing import Dict, Any, List, Optional
from pathlib import Path
from async_deepseek_analyzer import AsyncDeepSeekAnalyzer


class CommunityDescriptionGenerator:
    """
    ä½¿ç”¨å¼‚æ­¥å¹¶å‘DeepSeekåˆ†æç”Ÿæˆç¤¾åŒºåŠŸèƒ½æè¿°çš„ä¸“ç”¨ç±»
    """
    
    def __init__(self, max_concurrent_requests: int = 20, request_delay: float = 0.1):
        """
        åˆå§‹åŒ–ç¤¾åŒºæè¿°ç”Ÿæˆå™¨
        
        Args:
            max_concurrent_requests: æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
            request_delay: è¯·æ±‚é—´å»¶è¿Ÿ(ç§’)
        """
        self.logger = logging.getLogger(__name__)
        self.max_concurrent_requests = max_concurrent_requests
        self.request_delay = request_delay
        
        # åˆå§‹åŒ–å¼‚æ­¥DeepSeekåˆ†æå™¨
        try:
            self.deepseek_analyzer = AsyncDeepSeekAnalyzer(
                max_concurrent_requests=max_concurrent_requests,
                request_delay=request_delay
            )
            self.deepseek_available = self.deepseek_analyzer.is_available()
        except Exception as e:
            self.logger.warning(f"DeepSeek analyzer initialization failed: {e}")
            self.deepseek_analyzer = None
            self.deepseek_available = False
    
    async def generate_all_descriptions_async(self, communities_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¼‚æ­¥å¹¶å‘ç”Ÿæˆæ‰€æœ‰ç¤¾åŒºçš„åŠŸèƒ½æè¿°
        
        Args:
            communities_data: ç¤¾åŒºæ•°æ®å­—å…¸
            
        Returns:
            åŒ…å«æ‰€æœ‰ç¤¾åŒºæè¿°çš„å­—å…¸
        """
        if not self.deepseek_available:
            self.logger.warning("DeepSeek not available, generating basic descriptions")
            return self._generate_basic_descriptions(communities_data)
        
        start_time = time.time()
        total_communities = len(communities_data)
        
        self.logger.info(f"ğŸš€ Starting async generation of {total_communities} community descriptions...")
        self.logger.info(f"ğŸ“Š Concurrency settings: {self.max_concurrent_requests} max requests, {self.request_delay}s delay")
        
        try:
            # ä½¿ç”¨å¼‚æ­¥æ‰¹é‡åˆ†æ
            descriptions = await self.deepseek_analyzer.analyze_communities_batch_async(communities_data)
            
            elapsed_time = time.time() - start_time
            avg_time = elapsed_time / total_communities if total_communities > 0 else 0
            
            self.logger.info(f"âœ… Async community descriptions completed!")
            self.logger.info(f"â±ï¸  Total time: {elapsed_time:.2f}s")
            self.logger.info(f"ğŸ“ˆ Average time per community: {avg_time:.2f}s")
            self.logger.info(f"ğŸš€ Speedup vs sequential: ~{self.max_concurrent_requests}x")
            
            return descriptions
            
        except Exception as e:
            self.logger.error(f"âŒ Async description generation failed: {e}")
            return self._generate_basic_descriptions(communities_data)
    
    def generate_descriptions_sync(self, communities_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŒæ­¥è¿è¡Œå¼‚æ­¥æè¿°ç”Ÿæˆ (ä¾›éå¼‚æ­¥ç¯å¢ƒè°ƒç”¨)
        
        Args:
            communities_data: ç¤¾åŒºæ•°æ®å­—å…¸
            
        Returns:
            åŒ…å«æ‰€æœ‰ç¤¾åŒºæè¿°çš„å­—å…¸
        """
        try:
            # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥æ–¹æ³•
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                return loop.run_until_complete(self.generate_all_descriptions_async(communities_data))
            finally:
                loop.close()
                
        except Exception as e:
            self.logger.error(f"Error in sync wrapper: {e}")
            return self._generate_basic_descriptions(communities_data)
    
    def _generate_basic_descriptions(self, communities_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”ŸæˆåŸºç¡€ç¤¾åŒºæè¿° (ä¸ä½¿ç”¨AI)
        
        Args:
            communities_data: ç¤¾åŒºæ•°æ®å­—å…¸
            
        Returns:
            åŸºç¡€æè¿°å­—å…¸
        """
        descriptions = {}
        
        for community_id, community_data in communities_data.items():
            size = community_data.get('size', 0)
            cohesion = community_data.get('cohesion', 0)
            coupling = community_data.get('coupling', 0)
            nodes = community_data.get('nodes', [])
            
            # åˆ†ææ–‡ä»¶ç±»å‹åˆ†å¸ƒ
            file_types = self._analyze_file_types(nodes)
            
            # ç”ŸæˆåŸºç¡€æè¿°
            descriptions[community_id] = {
                "functionality": f"ç¤¾åŒº{community_id}åŒ…å«{size}ä¸ªä»£ç å…ƒç´ ï¼Œä¸»è¦æ¶‰åŠ{', '.join(file_types)}",
                "architecture_pattern": self._infer_pattern_from_nodes(nodes),
                "design_quality": self._calculate_design_quality(cohesion, coupling),
                "refactor_suggestions": self._generate_basic_suggestions(cohesion, coupling),
                "functional_tags": file_types,
                "external_dependencies": []
            }
        
        return descriptions
    
    def _analyze_file_types(self, nodes: List[str]) -> List[str]:
        """åˆ†æèŠ‚ç‚¹ä¸­çš„æ–‡ä»¶ç±»å‹åˆ†å¸ƒ"""
        file_patterns = {
            'test': ['test_', '_test', 'tests/'],
            'config': ['config', 'settings', 'env'],
            'api': ['api', 'endpoint', 'service'],
            'model': ['model', 'entity', 'schema'],
            'util': ['util', 'helper', 'common'],
            'ui': ['ui', 'view', 'component'],
            'core': ['core', 'base', 'main']
        }
        
        detected_types = set()
        
        for node in nodes:
            node_lower = node.lower()
            for type_name, patterns in file_patterns.items():
                if any(pattern in node_lower for pattern in patterns):
                    detected_types.add(type_name)
        
        return list(detected_types) if detected_types else ['general']
    
    def _infer_pattern_from_nodes(self, nodes: List[str]) -> str:
        """ä»èŠ‚ç‚¹æ¨æ–­æ¶æ„æ¨¡å¼"""
        if any('test' in node.lower() for node in nodes):
            return "testing"
        elif any('api' in node.lower() for node in nodes):
            return "api_layer"
        elif any('model' in node.lower() for node in nodes):
            return "data_model"
        elif any('service' in node.lower() for node in nodes):
            return "service_layer"
        else:
            return "functional_module"
    
    def _calculate_design_quality(self, cohesion: float, coupling: float) -> int:
        """è®¡ç®—è®¾è®¡è´¨é‡è¯„åˆ† (1-10)"""
        # é«˜å†…èšä½è€¦åˆå¾—åˆ†é«˜
        quality_score = (cohesion * 10) - (coupling * 20)
        return max(1, min(10, int(quality_score + 5)))
    
    def _generate_basic_suggestions(self, cohesion: float, coupling: float) -> List[str]:
        """ç”ŸæˆåŸºç¡€é‡æ„å»ºè®®"""
        suggestions = []
        
        if cohesion < 0.3:
            suggestions.append("å»ºè®®æé«˜æ¨¡å—å†…èšæ€§ï¼Œå°†ç›¸å…³åŠŸèƒ½ç»„ç»‡åœ¨ä¸€èµ·")
        
        if coupling > 0.3:
            suggestions.append("å»ºè®®é™ä½æ¨¡å—è€¦åˆåº¦ï¼Œå‡å°‘å¯¹å¤–éƒ¨æ¨¡å—çš„ä¾èµ–")
        
        if not suggestions:
            suggestions.append("å½“å‰æ¨¡å—è®¾è®¡åˆç†ï¼Œä¿æŒè‰¯å¥½çš„å†…èšæ€§å’Œä½è€¦åˆæ€§")
        
        return suggestions
    
    def save_descriptions_to_file(self, descriptions: Dict[str, Any], output_path: str):
        """
        ä¿å­˜ç¤¾åŒºæè¿°åˆ°æ–‡ä»¶
        
        Args:
            descriptions: ç¤¾åŒºæè¿°å­—å…¸
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜JSONæ ¼å¼
        json_path = output_file.with_suffix('.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(descriptions, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜Markdownæ ¼å¼
        md_path = output_file.with_suffix('.md')
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write("# ç¤¾åŒºåŠŸèƒ½æè¿°æŠ¥å‘Š\\n\\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n")
            f.write(f"æ€»ç¤¾åŒºæ•°: {len(descriptions)}\\n\\n")
            
            for i, (community_id, desc) in enumerate(descriptions.items(), 1):
                f.write(f"## {i}. ç¤¾åŒº {community_id}\\n\\n")
                f.write(f"**åŠŸèƒ½æè¿°**: {desc.get('functionality', 'N/A')}\\n\\n")
                f.write(f"**æ¶æ„æ¨¡å¼**: {desc.get('architecture_pattern', 'N/A')}\\n\\n")
                f.write(f"**è®¾è®¡è´¨é‡**: {desc.get('design_quality', 'N/A')}/10\\n\\n")
                
                suggestions = desc.get('refactor_suggestions', [])
                if suggestions:
                    f.write("**é‡æ„å»ºè®®**:\\n")
                    for suggestion in suggestions:
                        f.write(f"- {suggestion}\\n")
                    f.write("\\n")
                
                tags = desc.get('functional_tags', [])
                if tags:
                    f.write(f"**åŠŸèƒ½æ ‡ç­¾**: {', '.join(tags)}\\n\\n")
                
                f.write("---\\n\\n")
        
        self.logger.info(f"ğŸ“„ Community descriptions saved to:")
        self.logger.info(f"  - JSON: {json_path}")
        self.logger.info(f"  - Markdown: {md_path}")


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
async def test_async_community_description():
    """æµ‹è¯•å¼‚æ­¥ç¤¾åŒºæè¿°ç”Ÿæˆ"""
    
    # æ¨¡æ‹Ÿç¤¾åŒºæ•°æ® (ä½¿ç”¨çœŸå®çš„AgentFrameworkæ•°æ®ç»“æ„)
    test_communities = {
        "0": {
            "size": 26,
            "cohesion": 0.08,
            "coupling": 0.018867924528301886,
            "nodes": [
                "/home/guci/aiProjects/AgentFrameWork/enhancedAgent_v2.py:validate_variables",
                "/home/guci/aiProjects/AgentFrameWork/enhancedAgent_v2.py:_categorize_state_relevance",
                "/home/guci/aiProjects/AgentFrameWork/static_workflow/MultiStepAgent_v3.py:get_workflow_info"
            ]
        },
        "1": {
            "size": 24,
            "cohesion": 0.09782608695652174,
            "coupling": 0.01818181818181818,
            "nodes": [
                "/home/guci/aiProjects/AgentFrameWork/demo_agent_compression.py:chat_with_compression",
                "/home/guci/aiProjects/AgentFrameWork/message_compress.py:compress_messages",
                "/home/guci/aiProjects/AgentFrameWork/performance_monitor.py:decorator"
            ]
        }
    }
    
    # åˆ›å»ºç”Ÿæˆå™¨å¹¶æµ‹è¯•
    generator = CommunityDescriptionGenerator(max_concurrent_requests=3, request_delay=0.1)
    
    print("ğŸ§ª Testing async community description generation...")
    descriptions = await generator.generate_all_descriptions_async(test_communities)
    
    print("\\nğŸ“‹ Generated descriptions:")
    for comm_id, desc in descriptions.items():
        print(f"\\n{comm_id}: {desc['functionality']}")
    
    # ä¿å­˜ç»“æœ
    generator.save_descriptions_to_file(descriptions, "test_community_descriptions")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_async_community_description())